import { OpenAIEmbeddings } from "@langchain/openai";
import { HNSWLib } from "@langchain/community/vectorstores/hnswlib";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
import * as fs from "fs";
import * as path from "path";
import * as dotenv from "dotenv";

dotenv.config();

const VECTOR_STORE_PATH = "vector_store";

async function run() {
  console.log("ğŸš€ å¼€å§‹æ•°æ®å…¥åº“æµç¨‹ (LangChain)...");

  // 1. è¯»å–æ–‡æ¡£
  const docPath = path.join(__dirname, "../data/sample.md");
  if (!fs.existsSync(docPath)) {
    console.error(`âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: ${docPath}`);
    process.exit(1);
  }
  const text = fs.readFileSync(docPath, "utf-8");
  console.log("ğŸ“ æ–‡æ¡£è¯»å–æˆåŠŸ");

  // 2. åˆ‡ç‰‡ (Chunking)
  const splitter = new RecursiveCharacterTextSplitter({
    chunkSize: 512,
    chunkOverlap: 50,
  });
  const docs = await splitter.createDocuments([text]);
  console.log(`âœ‚ï¸  æ–‡æ¡£å·²åˆ‡åˆ†ä¸º ${docs.length} ä¸ªç‰‡æ®µ`);

  // 3. åˆå§‹åŒ– Embedding æ¨¡å‹ (Volcengine)
  // æ³¨æ„ï¼šVolcengine å…¼å®¹ OpenAI æ¥å£ï¼Œä½†éœ€è¦æŒ‡å®š modelName
  const embeddings = new OpenAIEmbeddings({
    apiKey: process.env.VOLCENGINE_API_KEY,
    configuration: {
      baseURL: process.env.VOLCENGINE_BASE_URL,
    },
    modelName: process.env.VOLCENGINE_EMBEDDING_MODEL,
  });
  console.log(`ğŸ§  ä½¿ç”¨ Embedding æ¨¡å‹: ${process.env.VOLCENGINE_EMBEDDING_MODEL}`);

  // 4. ç”Ÿæˆå‘é‡å¹¶å­˜å‚¨ (HNSWLib)
  console.log("ğŸ’¾ æ­£åœ¨ç”Ÿæˆå‘é‡å¹¶å­˜å‚¨...");
  const vectorStore = await HNSWLib.fromDocuments(docs, embeddings);

  await vectorStore.save(VECTOR_STORE_PATH);
  console.log(`âœ… å‘é‡åº“å·²ä¿å­˜è‡³ç›®å½•: ${VECTOR_STORE_PATH}`);
}

run().catch((error) => {
  console.error("âŒ å…¥åº“å¤±è´¥:", error);
  process.exit(1);
});
