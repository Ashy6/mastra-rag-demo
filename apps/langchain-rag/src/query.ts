import { ChatOpenAI, OpenAIEmbeddings } from "@langchain/openai";
import { HNSWLib } from "@langchain/community/vectorstores/hnswlib";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { PromptTemplate } from "@langchain/core/prompts";
import { RunnableSequence } from "@langchain/core/runnables";
import { formatDocumentsAsString } from "langchain/util/document";
import * as dotenv from "dotenv";

dotenv.config();

const VECTOR_STORE_PATH = "vector_store";

async function run() {
  const question = process.argv[2] || "LangChain RAG æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ";
  console.log(`â“ é—®é¢˜: ${question}`);

  // 1. åˆå§‹åŒ– Embedding æ¨¡å‹ (ç”¨äºæŸ¥è¯¢å‘é‡åŒ–)
  const embeddings = new OpenAIEmbeddings({
    apiKey: process.env.VOLCENGINE_API_KEY,
    configuration: {
      baseURL: process.env.VOLCENGINE_BASE_URL,
    },
    modelName: process.env.VOLCENGINE_EMBEDDING_MODEL,
  });

  // 2. åŠ è½½å‘é‡æ•°æ®åº“
  console.log("ğŸ“‚ åŠ è½½å‘é‡çŸ¥è¯†åº“...");
  let vectorStore;
  try {
    vectorStore = await HNSWLib.load(VECTOR_STORE_PATH, embeddings);
  } catch (error) {
    console.error("âŒ æ— æ³•åŠ è½½å‘é‡åº“ã€‚è¯·å…ˆè¿è¡Œ 'npm run ingest'ã€‚");
    process.exit(1);
  }

  // 3. åˆå§‹åŒ– Chat æ¨¡å‹ (Volcengine)
  const model = new ChatOpenAI({
    apiKey: process.env.VOLCENGINE_API_KEY,
    configuration: {
      baseURL: process.env.VOLCENGINE_BASE_URL,
    },
    modelName: process.env.VOLCENGINE_CHAT_MODEL,
    temperature: 0.7,
  });

  // 4. æ„å»º RAG Chain
  const retriever = vectorStore.asRetriever(2); // è·å–æœ€ç›¸å…³çš„ 2 ä¸ªåˆ‡ç‰‡

  const prompt = PromptTemplate.fromTemplate(`
    ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
    å¦‚æœä¸Šä¸‹æ–‡æ²¡æœ‰åŒ…å«è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œè¯·ç›´æ¥è¯´â€œæˆ‘ä¸çŸ¥é“â€ã€‚
    
    ä¸Šä¸‹æ–‡:
    {context}
    
    é—®é¢˜:
    {question}
    
    å›ç­”:
  `);

  const chain = RunnableSequence.from([
    {
      context: async (input: string) => {
        const relevantDocs = await retriever.invoke(input);
        console.log(`ğŸ” æ£€ç´¢åˆ° ${relevantDocs.length} æ¡ç›¸å…³ä¿¡æ¯`);
        return formatDocumentsAsString(relevantDocs);
      },
      question: (input: string) => input,
    },
    prompt,
    model,
    new StringOutputParser(),
  ]);

  // 5. æ‰§è¡ŒæŸ¥è¯¢
  console.log("ğŸ¤– æ€è€ƒä¸­...");
  const stream = await chain.stream(question);

  console.log("\nğŸ’¡ å›ç­”:");
  for await (const chunk of stream) {
    process.stdout.write(chunk);
  }
  console.log("\n");
}

run().catch((error) => {
  console.error("âŒ æŸ¥è¯¢å¤±è´¥:", error);
  process.exit(1);
});
