# Mastra RAG 智能知识库助手 - 产品需求文档 (PRD)

## 1. 项目背景

在当今信息爆炸的时代，企业和个人面临着海量文档管理的挑战。传统的关键词搜索难以理解语义，导致信息检索效率低下。基于 Mastra 框架的 RAG (Retrieval-Augmented Generation) 技术，我们可以构建一个能够理解文档内容、进行语义搜索并基于文档回答问题的智能助手。

## 2. 产品目标

构建一个基于 Mastra 的 RAG 智能 Agent，实现以下核心功能：

1. **知识摄入**：支持上传文本/Markdown 文档。
2. **知识处理**：自动对文档进行切片 (Chunking) 和向量化 (Embedding)。
3. **智能问答**：用户用自然语言提问，Agent 基于文档内容进行精准回答。
4. **可扩展性**：代码结构清晰，易于后续扩展更多数据源。

## 3. 用户角色

* **管理员**：负责上传和更新知识库文档。
* **普通用户**：通过对话界面查询信息。

## 4. 功能需求

### 4.1 核心功能 (MVP)

| ID | 功能模块 | 功能名称 | 详细描述 | 优先级 |
| :--- | :--- | :--- | :--- | :--- |
| F1 | 数据层 | 文档解析 | 使用 `MDocument` 解析 Markdown/Text 内容。 | P0 |
| F2 | 数据层 | 向量存储 | 将文档切片并存储到向量数据库。为了便于本地运行，本项目默认使用 **LibSQL** (文件型数据库)，但架构支持 PgVector。 | P0 |
| F3 | 逻辑层 | 语义检索 | 将用户问题转化为向量，在数据库中检索最相似的切片。 | P0 |
| F4 | 交互层 | 生成式问答 | 将检索到的上下文 + 用户问题发送给 LLM，生成最终答案。 | P0 |
| F5 | 交互层 | CLI 交互 | 提供命令行界面供用户测试问答效果。 | P1 |

### 4.2 非功能需求

* **响应速度**：检索过程应在 1秒内完成，生成过程视 LLM 速度而定。
* **准确性**：回答必须基于提供的文档，尽量减少幻觉。
* **代码规范**：遵循 TypeScript 最佳实践，模块化设计。

## 5. 技术架构

* **开发语言**：TypeScript
* **运行环境**：Node.js >= 18
* **核心框架**：Mastra (@mastra/core, @mastra/rag, @mastra/libsql)
* **向量模型**：OpenAI text-embedding-3-small
* **LLM 模型**：GPT-4o-mini
* **向量数据库**：LibSQL (本地文件模式) / 可选 PgVector

## 6. 验收标准

1. 能够成功运行 `npm install` 安装依赖。
2. 配置 `.env` 后，运行 `npm run ingest` 能在本地生成 `mastra.db` 并完成向量入库。
3. 运行 `npm run query "What is Mastra?"` 能准确输出基于文档的定义。
4. 运行 `ts-node src/scripts/test.ts` 通过自动化测试。
